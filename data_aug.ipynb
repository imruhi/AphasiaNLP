{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "# task: turn text into non-fluent aphasic speech, based on Misra et al (2022) \n",
    "# current: basic code, maybe try to speed up transformation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T14:14:56.595097800Z",
     "start_time": "2024-01-22T14:14:56.585099900Z"
    }
   },
   "id": "6e5928ec082fcfd2"
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "import numpy as np\n",
    "import random\n",
    "import pyphen\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T14:14:56.955158200Z",
     "start_time": "2024-01-22T14:14:56.598100100Z"
    }
   },
   "id": "53d51e52434633de"
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "vp_pattern = [ [{'POS': 'VERB', 'OP': '?'},\n",
    "           {'POS': 'ADV', 'OP': '*'},\n",
    "           {'POS': 'AUX', 'OP': '*'},\n",
    "           {'POS': 'VERB', 'OP': '+'}] ] \n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"Verb phrase\", vp_pattern)\n",
    "\n",
    "a = pyphen.Pyphen(lang='en')\n",
    "fillers = [\"ah [...] \", \"er [...] \", \"oh [...] \"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T14:14:56.971067700Z",
     "start_time": "2024-01-22T14:14:56.957560600Z"
    }
   },
   "id": "19cdffd5065cd02"
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "def aphasic_speech(text, doc):\n",
    "    n = 15\n",
    "    aphasic_utt = \"\"\n",
    "    \n",
    "    if len(text.split()) <= n:  \n",
    "        # get NPs\n",
    "        noun_phrases = set()\n",
    "        for nc in doc.noun_chunks:\n",
    "            for nop in [nc, doc[nc.root.left_edge.i:nc.root.right_edge.i+1]]:\n",
    "                noun_phrases.add(nop.text.strip())                   \n",
    "        print(noun_phrases)      \n",
    "        \n",
    "        # get VPs\n",
    "        verb_phrases = matcher(doc)\n",
    "        verb_phrases = [doc[start:end] for _, start, \n",
    "                        end in verb_phrases]\n",
    "        print(verb_phrases)\n",
    "        \n",
    "        try:\n",
    "            ratio = len(noun_phrases)/len(verb_phrases)\n",
    "        except:\n",
    "            print(\"Division by zero\")\n",
    "            return \n",
    "        print(ratio)\n",
    "        \n",
    "        X = np.random.uniform(0,1)\n",
    "        \n",
    "        if ratio > 2 and X <= 0.8:\n",
    "            # skip sentence\n",
    "            return aphasic_utt\n",
    "        \n",
    "        else:\n",
    "            # dont skip sentence\n",
    "            for tok in doc:\n",
    "                \n",
    "                filler_x = np.random.uniform(0,1)                \n",
    "                if len(aphasic_utt.split())%4 == 0 or filler_x > 0.5:\n",
    "                    # add filler\n",
    "                    aphasic_utt += random.choice(fillers)\n",
    "                \n",
    "                word_sub = np.random.uniform(0,1)\n",
    "                # if word_sub > 0.9:\n",
    "                    # TODO: substitution based on levenshtein distance\n",
    "                    \n",
    "                if tok.dep_ in [\"det\", \"prep\", \"cop\", \"aux\"]: \n",
    "                    # determiners, prepositions, copulas\n",
    "                    Y = np.random.uniform(0,1)\n",
    "                    if Y > 0.9:\n",
    "                        aphasic_utt += tok.text + \" \"\n",
    "                        \n",
    "                elif tok.pos_ in [\"ADJ\", \"ADV\"]:      \n",
    "                    # adjectives, adverbs\n",
    "                    Z = np.random.uniform(0,1)\n",
    "                    if Z > 0.5:\n",
    "                        aphasic_utt += tok.text + \" \"\n",
    "                \n",
    "                elif tok.pos_ == \"VERB\":\n",
    "                    # verbs\n",
    "                    aphasic_utt += tok.lemma_ + \" \"\n",
    "                \n",
    "                else:\n",
    "                    # all other pos\n",
    "                    aphasic_utt += tok.text + \" \"\n",
    "    \n",
    "    return aphasic_utt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T14:14:56.990760200Z",
     "start_time": "2024-01-22T14:14:56.975813600Z"
    }
   },
   "id": "941a3422465576bd"
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple\n",
      "PRON nsubj\n",
      "VERB ROOT\n",
      "DET det\n",
      "NOUN dobj\n",
      "PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "text1 = \"I want an apple.\"\n",
    "doc1 = nlp(text1)\n",
    "\n",
    "print(a.inserted('apple'))\n",
    "\n",
    "for tok in doc1:\n",
    "    print(tok.pos_, tok.dep_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T14:14:57.001909800Z",
     "start_time": "2024-01-22T14:14:56.989754300Z"
    }
   },
   "id": "d5f0e4ccdf64531d"
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'an apple', 'I'}\n",
      "[want]\n",
      "2.0\n",
      "oh [...] I want ah [...] er [...] apple ah [...] . \n"
     ]
    }
   ],
   "source": [
    "print(aphasic_speech(text1, doc1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T14:14:57.047876600Z",
     "start_time": "2024-01-22T14:14:57.003216Z"
    }
   },
   "id": "a3402831c9362bbc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
