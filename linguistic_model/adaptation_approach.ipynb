{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "# Based on results from Adaptation theory and non-fluent aphasia in english by Salis and Edwards (2004)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T13:49:50.551743200Z",
     "start_time": "2024-02-20T13:49:50.531104200Z"
    }
   },
   "id": "18232d89896a30ae"
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "from pattern.en import conjugate, lemma, lexeme, PRESENT, SG\n",
    "from spacy.matcher import Matcher\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T13:49:50.998492900Z",
     "start_time": "2024-02-20T13:49:50.547277200Z"
    }
   },
   "id": "f237ea2055319fba"
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "filepath = \"../preprocessing/data_control_preprocessed.csv\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T13:49:51.012962100Z",
     "start_time": "2024-02-20T13:49:50.999940300Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "df = pd.read_csv(filepath).dropna().reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T13:49:51.122361900Z",
     "start_time": "2024-02-20T13:49:51.015451300Z"
    }
   },
   "id": "b5497eabef9db6f3"
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "sentences = df[\"preprocessed_text\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T13:49:51.139021500Z",
     "start_time": "2024-02-20T13:49:51.125362100Z"
    }
   },
   "id": "bba4a0221998a9ef"
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "dets = {'Art': ['a', 'an', 'the', ''],\n",
    "           'Dem': ['this', 'that', 'these', 'those', ''],\n",
    "           'Poss': ['my', 'your', 'his', 'her', 'its', 'our', 'their', '']}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T13:49:51.156664500Z",
     "start_time": "2024-02-20T13:49:51.141231100Z"
    }
   },
   "id": "a8681817efd09f21"
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "def det_sub(det):\n",
    "    for _, detrms in dets.items():\n",
    "        if det.lower() in detrms:\n",
    "            y = [j for j in detrms if det!=j]\n",
    "            return random.choice(y)\n",
    "    return \"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T13:49:51.169993800Z",
     "start_time": "2024-02-20T13:49:51.156664500Z"
    }
   },
   "id": "66f4ce3548abe7ee"
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "def handle_determiner(tok):\n",
    "    x = np.random.uniform(0,1)\n",
    "    # 3% of determiners were substituted\n",
    "    if x >= 0.97:\n",
    "        if tok.pos_ == \"DET\" or \"Dem\" in tok.morph.get('PronType') or \"Yes\" in tok.morph.get('Poss'):\n",
    "            return det_sub(tok.text) + \" \"\n",
    "    # 19% determiners were omitted\n",
    "    elif x >= 0.81:\n",
    "        return \" \"\n",
    "    return tok.text + \" \""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T13:49:51.189515800Z",
     "start_time": "2024-02-20T13:49:51.173007200Z"
    }
   },
   "id": "54c008b5de8d4253"
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "def handle_verb(tok):\n",
    "    # TODO handle the copula, auxiliary and lexical tense/bound morphemes\n",
    "    x = np.random.uniform(0,1)\n",
    "    # 4% of verbs were substituted (tense error) \n",
    "    if x >= 0.96:\n",
    "        # TODO tense sub based on frequency?\n",
    "        return conjugate(verb=tok.text,tense=PRESENT,number=SG) + \" \" \n",
    "    # 17% determiners were omitted\n",
    "    elif x >= 0.83:\n",
    "        return \" \"\n",
    "    return tok.text + \" \""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T13:49:51.204515500Z",
     "start_time": "2024-02-20T13:49:51.189515800Z"
    }
   },
   "id": "68fa2e55a62234fb"
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "def handle_preposition(tok):\n",
    "    x = np.random.uniform(0,1)\n",
    "    # 2% of prepositions were substituted\n",
    "    if x >= 0.98:\n",
    "        # TODO substitute\n",
    "        pass\n",
    "    # 37% of prepositions were omitted\n",
    "    elif x >= 0.63:\n",
    "        return \" \"\n",
    "    return tok.text + \" \""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T13:49:51.219288900Z",
     "start_time": "2024-02-20T13:49:51.202514700Z"
    }
   },
   "id": "ac336a16bcbfa7ee"
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "def handle_person_pron(tok):\n",
    "    x = np.random.uniform(0,1)\n",
    "    # 27% of personal pronouns were omitted\n",
    "    if x >= 0.73:\n",
    "        return \" \"\n",
    "    return tok.text + \" \""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T13:49:51.234287900Z",
     "start_time": "2024-02-20T13:49:51.219288900Z"
    }
   },
   "id": "63c9ea6356f3bc60"
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "def aphasic_speech(sentence):\n",
    "    vp_pattern = [[{'POS': 'VERB', 'OP': '?'},\n",
    "                   {'POS': 'ADV', 'OP': '*'},\n",
    "                   {'POS': 'AUX', 'OP': '*'},\n",
    "                   {'POS': 'VERB', 'OP': '+'}]]\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    matcher.add(\"Verb phrase\", vp_pattern)\n",
    "    n = 15\n",
    "    aphasic_utt = \"\"\n",
    "    doc = nlp(sentence)\n",
    "    # print(sentence, len(sentence.split()))\n",
    "    if len(sentence.split()) <= n:\n",
    "        # get NPs\n",
    "        noun_phrases = set()\n",
    "\n",
    "        for nc in doc.noun_chunks:\n",
    "            for nop in [nc, doc[nc.root.left_edge.i:nc.root.right_edge.i + 1]]:\n",
    "                noun_phrases.add(nop.text.strip())\n",
    "                # get VPs\n",
    "        verb_phrases = matcher(doc)\n",
    "        verb_phrases = [doc[start:end] for _, start, end in verb_phrases]\n",
    "\n",
    "        try:\n",
    "            ratio = len(noun_phrases) / len(verb_phrases)\n",
    "        except:\n",
    "            # print(\"Division by zero\")\n",
    "            return aphasic_utt\n",
    "\n",
    "        X = np.random.uniform(0, 1)\n",
    "        # print(ratio, X)\n",
    "        if ratio > 2 and X <= 0.8:\n",
    "            # skip sentence\n",
    "            return aphasic_utt\n",
    "    \n",
    "        else:\n",
    "            # don't skip sentence\n",
    "            for tok in doc:\n",
    "                if tok.pos_ in [\"DET\", \"PRON\"]:\n",
    "                    aphasic_utt += handle_determiner(tok)          \n",
    "                elif tok.pos_ == \"VERB\":\n",
    "                    aphasic_utt += handle_verb(tok)\n",
    "                elif tok.dep_ == \"prep\" or tok.pos_ == \"ADP\":\n",
    "                    aphasic_utt += handle_preposition(tok)\n",
    "                elif tok.morph.get('Case') == 'Nom' and tok.morph.get('Person') == 1:\n",
    "                    aphasic_utt += handle_person_pron(tok)\n",
    "                    \n",
    "                else:\n",
    "                    aphasic_utt += tok.text + \" \"\n",
    "    \n",
    "    return aphasic_utt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T13:49:51.250230200Z",
     "start_time": "2024-02-20T13:49:51.234287900Z"
    }
   },
   "id": "908fae5d5c2840bd"
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "aphasic = []\n",
    "for sent in sentences:\n",
    "    modify = aphasic_speech(sent)\n",
    "    if modify is not None and modify != '':\n",
    "        # remove excess whitespaces (and capitalize first word?)\n",
    "        modify = re.sub(r'\\s([?.!\"](?:\\s|$))', r'\\1', modify)\n",
    "        modify = \" \".join(modify.split())\n",
    "        aphasic.append(modify)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T13:52:11.579878300Z",
     "start_time": "2024-02-20T13:49:51.253230500Z"
    }
   },
   "id": "7cd19f299b26d5ce"
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"preprocessed_text\": aphasic})\n",
    "df.to_csv(\"../classifiers/test.csv\", sep=',',index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T13:52:11.625913900Z",
     "start_time": "2024-02-20T13:52:11.583192600Z"
    }
   },
   "id": "931a811472310fcf"
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6059646987218503"
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aphasic)/len(sentences)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T13:52:11.642298800Z",
     "start_time": "2024-02-20T13:52:11.626921100Z"
    }
   },
   "id": "f987e3a5a060549c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
