{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8decd97b993c427",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Imports  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f1366e7aa1dd212",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:48:24.632010900Z",
     "start_time": "2024-04-23T09:48:21.262046500Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer \n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "import seaborn as sns       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ce3af904743ee26",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:48:24.678586700Z",
     "start_time": "2024-04-23T09:48:24.663203700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cded5d3cb3bb09e0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:48:24.736389400Z",
     "start_time": "2024-04-23T09:48:24.679708400Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"../models/roberta_finetuned_reverse_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "288e770542a6325e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:48:27.643914600Z",
     "start_time": "2024-04-23T09:48:24.697185600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-CoLA were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"textattack/roberta-base-CoLA\", return_tensor=\"pt\")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "id2label = {0: \"CONTROL\", 1: \"BROCA\"}\n",
    "label2id = {\"CONTROL\": 0, \"BROCA\": 1}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"textattack/roberta-base-CoLA\", num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6968fd60529a4cd0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:48:27.691001500Z",
     "start_time": "2024-04-23T09:48:27.627975300Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset_filename = \"../../preprocessing/data/processed_merge.csv\"\n",
    "dataset_filename = \"../../linguistic_model/data/test_merge.csv\"\n",
    "data = pd.read_csv(dataset_filename, encoding='utf8', index_col=False)#.drop(['Unnamed: 0','Unnamed: 0.1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cba941e5823a34d0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:48:27.710955Z",
     "start_time": "2024-04-23T09:48:27.675172500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                 preprocessed_text  label\n0      see my parents were not very i do not know.      0\n1                   they are telling you that why.      0\n2                             she was in remedial.      0\n3                                  which is which.      0\n4                         it is thirty thirty air.      1\n...                                            ...    ...\n23186                         and then he kept it?      0\n23187                                      mexico.      1\n23188                              watch this now.      0\n23189            i was afraid th a seagull got me.      0\n23190                      i do not see how it is.      0\n\n[23191 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>preprocessed_text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>see my parents were not very i do not know.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>they are telling you that why.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>she was in remedial.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>which is which.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>it is thirty thirty air.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>23186</th>\n      <td>and then he kept it?</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23187</th>\n      <td>mexico.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>23188</th>\n      <td>watch this now.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23189</th>\n      <td>i was afraid th a seagull got me.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23190</th>\n      <td>i do not see how it is.</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>23191 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d88c1cf33e6ee36",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:48:27.770656800Z",
     "start_time": "2024-04-23T09:48:27.706633800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "23191"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caca98d726df10d6",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:48:27.770656800Z",
     "start_time": "2024-04-23T09:48:27.722764100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "label\n0    18726\n1     4465\nName: count, dtype: int64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there is the same data imbalance ratio\n",
    "data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f39e4e0f4242d32e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:48:27.864984100Z",
     "start_time": "2024-04-23T09:48:27.738516Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24dc19496ebae57",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:48:27.912305Z",
     "start_time": "2024-04-23T09:48:27.786598200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['preprocessed_text', 'label'],\n    num_rows: 23191\n})"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1d26f8ed7628ddf",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:48:27.959647600Z",
     "start_time": "2024-04-23T09:48:27.802096Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    metrics = [\"accuracy\", \"recall\", \"precision\", \"f1\"] #List of metrics to return\n",
    "    metric={}\n",
    "    for met in metrics:\n",
    "       metric[met] = evaluate.load(met)\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    metric_res={}\n",
    "    for met in metrics:\n",
    "       metric_res[met]=metric[met].compute(predictions=predictions, references=labels)[met]\n",
    "    print(metric_res)\n",
    "    return metric_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c5424bef5910ed6",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:48:27.959647600Z",
     "start_time": "2024-04-23T09:48:27.818099800Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"preprocessed_text\"], padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e968036da2524",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:48:28.940859700Z",
     "start_time": "2024-04-23T09:48:27.833732200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/23191 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b8e3fd5ca37c4acd901795743e87a277"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_data = dataset.map(preprocess_function, batched=True).with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26c079af78f208bd",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:48:28.959020400Z",
     "start_time": "2024-04-23T09:48:28.944439900Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_data_split = tokenized_data.train_test_split(test_size=0.2, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcdcf5ff28e237a1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:48:28.996460900Z",
     "start_time": "2024-04-23T09:48:28.959020400Z"
    }
   },
   "outputs": [],
   "source": [
    "# 70% train, 30% test + valid\n",
    "train_testvalid = tokenized_data.train_test_split(test_size=0.2, seed=42)\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5, seed=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "tokenized_data_split = DatasetDict({\n",
    "    \"train\": train_testvalid[\"train\"],\n",
    "    \"test\": test_valid[\"test\"],\n",
    "    \"valid\": test_valid[\"train\"]})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:48:29.011552800Z",
     "start_time": "2024-04-23T09:48:28.995463800Z"
    }
   },
   "id": "efba20bd3e70b25d"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['preprocessed_text', 'label', 'input_ids', 'attention_mask'],\n        num_rows: 18552\n    })\n    test: Dataset({\n        features: ['preprocessed_text', 'label', 'input_ids', 'attention_mask'],\n        num_rows: 2320\n    })\n    valid: Dataset({\n        features: ['preprocessed_text', 'label', 'input_ids', 'attention_mask'],\n        num_rows: 2319\n    })\n})"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:48:29.069008500Z",
     "start_time": "2024-04-23T09:48:29.011045300Z"
    }
   },
   "id": "9de3787187630605"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3ff31fdb9094677",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:52:29.590968900Z",
     "start_time": "2024-04-23T09:48:29.021335Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imruh\\miniconda3\\envs\\thesis\\lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='5800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/5800 : < :, Epoch 0.00/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_5044\\67081253.py\u001B[0m in \u001B[0;36m<cell line: 26>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     24\u001B[0m )\n\u001B[0;32m     25\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 26\u001B[1;33m \u001B[0mtrainer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     27\u001B[0m \u001B[0mtrainer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel_name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\thesis\\lib\\site-packages\\transformers\\trainer.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[0;32m   1624\u001B[0m                 \u001B[0mhf_hub_utils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0menable_progress_bars\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1625\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1626\u001B[1;33m             return inner_training_loop(\n\u001B[0m\u001B[0;32m   1627\u001B[0m                 \u001B[0margs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1628\u001B[0m                 \u001B[0mresume_from_checkpoint\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mresume_from_checkpoint\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\thesis\\lib\\site-packages\\transformers\\trainer.py\u001B[0m in \u001B[0;36m_inner_training_loop\u001B[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   2017\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2018\u001B[0m                     \u001B[1;31m# Optimizer step\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2019\u001B[1;33m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2020\u001B[0m                     \u001B[0moptimizer_was_run\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0maccelerator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptimizer_step_was_skipped\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2021\u001B[0m                     \u001B[1;32mif\u001B[0m \u001B[0moptimizer_was_run\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\thesis\\lib\\site-packages\\accelerate\\optimizer.py\u001B[0m in \u001B[0;36mstep\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    147\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_accelerate_step_called\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    148\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 149\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclosure\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    150\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0maccelerator_state\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdistributed_type\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0mDistributedType\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mXLA\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    151\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgradient_state\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_xla_gradients_synced\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\thesis\\lib\\site-packages\\torch\\optim\\lr_scheduler.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     73\u001B[0m                 \u001B[0minstance\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_step_count\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     74\u001B[0m                 \u001B[0mwrapped\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__get__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minstance\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcls\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 75\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mwrapped\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     76\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     77\u001B[0m             \u001B[1;31m# Note that the returned function here is no longer a bound method,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\thesis\\lib\\site-packages\\torch\\optim\\optimizer.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    383\u001B[0m                             )\n\u001B[0;32m    384\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 385\u001B[1;33m                 \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    386\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_optimizer_step_code\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    387\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\thesis\\lib\\site-packages\\torch\\optim\\optimizer.py\u001B[0m in \u001B[0;36m_use_grad\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     74\u001B[0m             \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mset_grad_enabled\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdefaults\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'differentiable'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     75\u001B[0m             \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dynamo\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgraph_break\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 76\u001B[1;33m             \u001B[0mret\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     77\u001B[0m         \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     78\u001B[0m             \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dynamo\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgraph_break\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\thesis\\lib\\site-packages\\torch\\optim\\adamw.py\u001B[0m in \u001B[0;36mstep\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    185\u001B[0m             )\n\u001B[0;32m    186\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 187\u001B[1;33m             adamw(\n\u001B[0m\u001B[0;32m    188\u001B[0m                 \u001B[0mparams_with_grad\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    189\u001B[0m                 \u001B[0mgrads\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\thesis\\lib\\site-packages\\torch\\optim\\adamw.py\u001B[0m in \u001B[0;36madamw\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[0;32m    337\u001B[0m         \u001B[0mfunc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_single_tensor_adamw\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    338\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 339\u001B[1;33m     func(\n\u001B[0m\u001B[0;32m    340\u001B[0m         \u001B[0mparams\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    341\u001B[0m         \u001B[0mgrads\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\thesis\\lib\\site-packages\\torch\\optim\\adamw.py\u001B[0m in \u001B[0;36m_multi_tensor_adamw\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001B[0m\n\u001B[0;32m    538\u001B[0m         \u001B[1;31m# wrapped it once now. The alpha is required to assure we go to the right overload.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    539\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mdevice_state_steps\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_cpu\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 540\u001B[1;33m             \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_foreach_add_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice_state_steps\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1.0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'cpu'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0malpha\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1.0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    541\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    542\u001B[0m             \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_foreach_add_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice_state_steps\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    use_cpu = False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data_split[\"train\"],\n",
    "    eval_dataset=tokenized_data_split[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd826e366d3392b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-23T09:52:29.587731100Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4784af9a51b005",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9189d00002d778f9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-23T09:52:29.589354100Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, return_tensor=\"pt\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ede310c0ba2c77",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-23T09:52:29.590968900Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences = tokenized_data_split[\"test\"][\"preprocessed_text\"]\n",
    "true_labels = tokenized_data_split[\"test\"][\"label\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf076f2d3e9071e0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-23T09:52:29.592949100Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_labels = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\").input_ids.to(device) \n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs).logits\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    pred_labels.append(predicted_class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec04b8a0331f1ed",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-23T09:52:29.593750300Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(true_labels, pred_labels, normalize='true')\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "ConfusionMatrixDisplay.from_predictions(true_labels, pred_labels, normalize=\"true\", cmap=plt.cm.Blues)\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(true_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-23T09:52:29.594501200Z"
    }
   },
   "id": "6a38c1a7d1d78b55"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfea9d986d8e4e1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:52:29.632003400Z",
     "start_time": "2024-04-23T09:52:29.596986500Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_score(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9a350d3c05122e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-23T09:52:29.596986500Z"
    }
   },
   "outputs": [],
   "source": [
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1 = (2 * precision * recall)/ (precision+recall)\n",
    "print(precision) \n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b372717bd48a479d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T13:33:30.731676300Z",
     "start_time": "2024-02-27T13:33:30.711678200Z"
    },
    "collapsed": false
   },
   "source": [
    "# Feature visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42df4e6fa6a3ab63",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-23T09:52:29.599493500Z"
    }
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
    "# import torch\n",
    "# \n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name, return_tensor=\"pt\")\n",
    "# model = AutoModel.from_pretrained(model_name)\n",
    "# device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40b88034bf9bdb5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-23T09:52:29.599493500Z"
    }
   },
   "outputs": [],
   "source": [
    "# def extract_hidden_states(batch):\n",
    "#     sentences = [x for x in batch[\"modified\"]]\n",
    "#     with torch.no_grad():\n",
    "#         inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True).input_ids.to(device)\n",
    "#         last_hidden_state = model(inputs).last_hidden_state\n",
    "# \n",
    "#     return {\"hidden state\": last_hidden_state[:, 0].cpu().numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dd5b774ddf8466",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-23T09:52:29.599493500Z"
    }
   },
   "outputs": [],
   "source": [
    "# import gc\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f4394defd64749",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-23T09:52:29.603555200Z"
    }
   },
   "outputs": [],
   "source": [
    "# hidden = tokenized_data_split.map(\n",
    "#     extract_hidden_states, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a152ad631bfaa816",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-23T09:52:29.603555200Z"
    }
   },
   "outputs": [],
   "source": [
    "# hidden.save_to_disk('../models/bert_dataset_c4_reverse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b097eaa230a4491d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-23T09:52:29.603555200Z"
    }
   },
   "outputs": [],
   "source": [
    "hidden[\"test\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee314912a3c95858",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-23T09:52:29.603555200Z"
    }
   },
   "outputs": [],
   "source": [
    "print(np.array(hidden[\"train\"][\"hidden state\"]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f05890fe30c5763",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-23T09:52:29.603555200Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_train = np.array(hidden[\"train\"][\"hidden state\"])\n",
    "y_train = np.array(hidden[\"train\"][\"label\"])\n",
    "\n",
    "X_test = np.array(hidden[\"test\"][\"hidden state\"])\n",
    "y_test = np.array(hidden[\"test\"][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07f8f9bfadf1f07",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-23T09:52:29.603555200Z"
    }
   },
   "outputs": [],
   "source": [
    "# reduce to 2d for visualization\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "x_scaled = MinMaxScaler().fit_transform(X_train)\n",
    "x_2d = pca.fit_transform(x_scaled)\n",
    "x_2d.shape\n",
    "\n",
    "x_scaled1 = MinMaxScaler().fit_transform(X_test)\n",
    "x_2d1 = pca.fit_transform(x_scaled1)\n",
    "x_2d1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78358214e289c61",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-23T09:52:29.603555200Z"
    }
   },
   "outputs": [],
   "source": [
    "# reduce to 3d for visualization\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "x_scaled = MinMaxScaler().fit_transform(X_train)\n",
    "x_3d = pca.fit_transform(x_scaled)\n",
    "x_3d.shape\n",
    "\n",
    "x_scaled1 = MinMaxScaler().fit_transform(X_test)\n",
    "x_3d1 = pca.fit_transform(x_scaled1)\n",
    "x_3d1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fa5db541f9bb2b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-23T09:52:29.609920500Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2d viz\n",
    "fig, ax = plt.subplots(2, 2, figsize=(7, 5))\n",
    "ax = ax.flatten()\n",
    "cmaps = [\"blue\", \"orange\"]\n",
    "labels = set([x.item() for x in tokenized_data_split[\"train\"][\"label\"]])\n",
    "\n",
    "for i, (label, cmap) in enumerate(zip(labels, cmaps)):\n",
    "    x_2d_sub = x_2d[y_train == i]\n",
    "    ax[i].scatter(x_2d_sub[:, 0], x_2d_sub[:, 1], color=cmap)\n",
    "    ax[i].set_title(id2label[label] +\" TRAIN\")\n",
    "    \n",
    "for i, (label, cmap) in enumerate(zip(labels, cmaps)):\n",
    "    x_2d_sub1 = x_2d1[y_test == i]\n",
    "    ax[i+2].scatter(x_2d_sub1[:, 0], x_2d_sub1[:, 1], color=cmap)\n",
    "    ax[i+2].set_title(id2label[label] +\" TEST\" )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ee6b60b009c571",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Shows us that there might be an overlap in control text and broca text which indistinguishable to the model (so model goes with control as sort of default strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f129d6059f201e9b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-23T09:52:29.609920500Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3d vis\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, subplot_kw={\"projection\": \"3d\"}, figsize=(8, 6))\n",
    "ax = ax.flatten()\n",
    "cmaps = [\"blue\", \"orange\"]\n",
    "labels = set([x.item() for x in tokenized_data_split[\"train\"][\"label\"]])\n",
    "\n",
    "for i, (label, cmap) in enumerate(zip(labels, cmaps)):\n",
    "    x_3d_sub = x_3d[y_train == i]\n",
    "    ax[i].scatter(x_3d_sub[:, 0], x_3d_sub[:, 1], color=cmap)\n",
    "    ax[i].set_title(id2label[label]+\" TRAIN\")\n",
    "    \n",
    "for i, (label, cmap) in enumerate(zip(labels, cmaps)):\n",
    "    x_3d_sub1 = x_3d1[y_test == i]\n",
    "    ax[i+2].scatter(x_3d_sub1[:, 0], x_3d_sub1[:, 1], color=cmap)\n",
    "    ax[i+2].set_title(id2label[label]+\" TEST\" )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2d2dc9e35e72b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T13:35:11.025219100Z",
     "start_time": "2024-02-27T13:35:10.958474500Z"
    },
    "collapsed": false
   },
   "source": [
    "# Attention viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd15c9abb7a65134",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-23T09:52:29.609920500Z"
    }
   },
   "outputs": [],
   "source": [
    "from bertviz import model_view, head_view\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, return_tensor=\"pt\")\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16593d5c50e2ccdb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### For control sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f7d23ea59f9d2a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-23T09:52:29.609920500Z"
    }
   },
   "outputs": [],
   "source": [
    "input = tokenizer.encode(sentences[0], return_tensors=\"pt\")\n",
    "output = model(input, output_attentions=True)\n",
    "\n",
    "attention = output[-1]\n",
    "tokens = tokenizer.convert_ids_to_tokens(input[0]) \n",
    "model_view(attention, tokens)\n",
    "print(sentences[0], true_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb0aef809127cec",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### For broca sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9205ee88774675f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-23T09:52:29.609920500Z"
    }
   },
   "outputs": [],
   "source": [
    "input = tokenizer.encode(sentences[8], return_tensors=\"pt\")\n",
    "output = model(input, output_attentions=True)\n",
    "\n",
    "attention = output[-1]\n",
    "tokens = tokenizer.convert_ids_to_tokens(input[0]) \n",
    "model_view(attention, tokens)\n",
    "print(sentences[8], true_labels[8])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
